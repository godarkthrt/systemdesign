# ğŸ§© Step 6: High Availability (HA) & Fault Tolerance (FT)

> Design systems that stay up even when parts fail.  
> Think: **"How can my system survive hardware failure, network issues, or traffic spikes?"**

---

## ğŸ”¹ 1. Key Concepts

| Concept           | Description                                                            |
| ----------------- | ---------------------------------------------------------------------- |
| High Availability | System remains accessible (uptime) even when failures occur            |
| Fault Tolerance   | System continues working correctly even if a component fails           |
| Redundancy        | Extra components to replace failures (active-passive or active-active) |
| Failover          | Automatic switch to a backup instance/node                             |
| Load Balancing    | Distribute traffic across healthy instances                            |
| Health Checks     | Probes to detect failure and remove bad nodes from rotation            |

---

## ğŸ“¶ 2. Availability Targets

| SLA Target        | Downtime per month |
| ----------------- | ------------------ |
| 99.9% (3 nines)   | ~43 minutes        |
| 99.99% (4 nines)  | ~4.3 minutes       |
| 99.999% (5 nines) | ~26 seconds        |

ğŸ”¹ FAANG targets often start at 4â€“5 nines for critical services.

---

## ğŸ§  3. Techniques for High Availability

---

### ğŸ” Load Balancing

Distributes traffic across multiple instances.

| Type        | Description                  |
| ----------- | ---------------------------- |
| Round Robin | Equal distribution           |
| Least Conn  | Send to least busy instance  |
| Geo-based   | Route based on user location |

âœ… Use with health checks to avoid routing to bad nodes.

---

### ğŸ—ƒï¸ Redundancy & Replication

- **DB Replication** (read replicas, failover secondaries)
- **Multi-AZ / Multi-region deployment** for resilience
- **Stateless services** can be restarted or scaled easily

---

### ğŸ”„ Auto Healing & Failover

| Component        | Technique                            |
| ---------------- | ------------------------------------ |
| VM / Pod Failure | Auto-restart via Kubernetes / ECS    |
| DB Failure       | Promote secondary (RDS, MySQL group) |
| Service Failure  | Reroute traffic, restart container   |

âœ… Use **orchestration tools** (like Kubernetes) to self-heal and reschedule services.

---

### ğŸ”Œ Circuit Breakers

Prevent cascading failures:

- **Trip** when error threshold is exceeded
- Temporarily **block calls** to the failing component
- **Retry** after cool-down

ğŸ› ï¸ Libraries: Netflix Hystrix (deprecated), Resilience4j

---

### ğŸ”¥ Graceful Degradation

System reduces functionality without total failure.

| Scenario             | Fallback                  |
| -------------------- | ------------------------- |
| Search service down  | Return cached results     |
| Recommendations fail | Show popular items        |
| Payment gateway down | Save cart for retry later |

---

### ğŸŒ Multi-Region Deployments

For ultra-high availability:

- **Active-Active**: All regions serve live traffic
- **Active-Passive**: One region on standby
- **Latency-based routing** via DNS (e.g., AWS Route53)

ğŸ“Œ Handle **data consistency** and **replication lag** in this model.

---

## ğŸ§ª 4. Monitoring & Detection (Support Layer)

We already covered this as a full section, but recap here for context:

| Layer    | Example Tools          | Use                  |
| -------- | ---------------------- | -------------------- |
| Metrics  | Prometheus, CloudWatch | Track service health |
| Logs     | ELK, Datadog Logs      | Debug failure causes |
| Traces   | Jaeger, Zipkin         | Root-cause latency   |
| Alerting | PagerDuty, OpsGenie    | On-call notification |

---

## ğŸ¯ FAANG Mock Interview Questions

---

### â“ Question 1:

**"Your system must have 99.99% availability. How would you design it?"**

âœ… Talking Points:

- Multi-AZ deployment
- Load-balanced replicas
- Auto-healing instances
- Redundant DB with failover
- Monitoring + alerts for failures

---

### â“ Question 2:

**"Explain how youâ€™d design a fault-tolerant microservice that depends on another slow or failing service."**

âœ… Answer:

- Use circuit breaker around the dependency
- Timeout and retry logic with backoff
- Return fallback response (graceful degradation)
- Isolate dependency calls via queue or bulkhead

---

### â“ Question 3:

**"Whatâ€™s the difference between HA and FT?"**

âœ… Sample Answer:

- HA ensures **uptime** via redundancy + load balancing
- FT ensures **correctness** despite partial failures
- FT is a _subset_ or an _implementation_ strategy for HA

---

## ğŸ’¡ Real-World Systems

| Company | Practice                                               |
| ------- | ------------------------------------------------------ |
| Netflix | Chaos Monkey for resilience testing                    |
| Amazon  | Zones + regions + retries everywhere                   |
| Google  | Borg + SRE handbooks define HA practices               |
| Uber    | Multi-region service mesh + graceful fallback patterns |

---

## âœ… Summary Checklist

| Area                 | Best Practice                                     |
| -------------------- | ------------------------------------------------- |
| Load Balancing       | Use L7/L4 with health checks                      |
| Redundancy           | N+1 replicas, read replicas, cross-region backups |
| Auto-Healing         | Kubernetes, ECS, VM orchestration                 |
| Circuit Breaker      | Use Resilience4j, handle timeouts + retries       |
| Graceful Degradation | Fallback paths for core services                  |
| Monitoring           | Alert on high error rate or latency spikes        |

---
